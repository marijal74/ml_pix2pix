{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from src.discriminator import Discriminator\n",
    "from src.generator import UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_comparison = nn.BCEWithLogitsLoss() \n",
    "L1_loss = nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator_step(discriminator: Discriminator, generator:UNet, inputs, targets, opt, device):\n",
    "    opt.zero_grad()\n",
    "\n",
    "    # real image loss\n",
    "    output = discriminator(inputs, targets)\n",
    "    label = torch.ones(size = output.shape, dtype=torch.float, device=device)\n",
    "        \n",
    "    real_loss = loss_comparison(output, label)\n",
    "\n",
    "    gen_image = generator(inputs).detach()\n",
    "\n",
    "    # fake image loss\n",
    "    fake_output = discriminator(inputs, gen_image)\n",
    "    fake_label = torch.zeros(size = fake_output.shape, dtype=torch.float, device=device) \n",
    "    \n",
    "    fake_loss = loss_comparison(fake_output, fake_label)\n",
    "\n",
    "    total_loss = (real_loss + fake_loss)/2\n",
    "\n",
    "    total_loss.backward()\n",
    "    \n",
    "    opt.step()\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_training_step(discriminator: Discriminator, generator:UNet, inputs, targets, opt, device, L1_lambda = 100):\n",
    "          \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    generated_image = generator(inputs)\n",
    "    \n",
    "    disc_output = discriminator(inputs, generated_image)\n",
    "    desired_output = torch.ones(size = disc_output.shape, dtype=torch.float, device=device)\n",
    "    \n",
    "    generator_loss = loss_comparison(disc_output, desired_output) + L1_lambda * torch.abs(generated_image-targets).sum()\n",
    "    generator_loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return generator_loss, generated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimizer(parameters):\n",
    "    lr=0.0002 \n",
    "    beta1=0.5\n",
    "    beta2=0.999\n",
    "    return optim.Adam(parameters, lr=lr, betas=(beta1, beta2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
